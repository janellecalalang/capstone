[
  {
    "objectID": "results/RQ3.html",
    "href": "results/RQ3.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All Code\n\n\n\n\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import pearsonr\n\npath = \"/Users/janellemarie/datasets/\"\n\nsales = pd.read_csv(path + \"quarterly_sales.csv\")\nhm_sales = pd.read_csv(path + \"hm_quarterly_sales_converted.csv\")\nhm_sales = hm_sales.rename(columns={\"Net Sales (USD Millions)\": \"Net Sales ($ Millions)\"})\n\ncombined = pd.concat([sales, hm_sales], ignore_index=True)\ncombined[\"Net Sales ($ Millions)\"] = combined[\"Net Sales ($ Millions)\"].astype(str).str.replace(\",\", \"\").astype(float)\ncombined[\"Brand\"] = combined[\"Brand\"].str.strip().replace(\"Gap Inc.\", \"Gap\")\n\nquarter_map = {\"Q1\": \"01\", \"Q2\": \"04\", \"Q3\": \"07\", \"Q4\": \"10\"}\ncombined[\"Month\"] = combined[\"Fiscal Quarter\"].map(quarter_map)\ncombined[\"Date\"] = pd.to_datetime(combined[\"Year\"].astype(str) + \"-\" + combined[\"Month\"] + \"-01\")\n\nmonthly_sales = combined.groupby([\"Date\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().reset_index()\n\nfiles = [\n    \"abercrombie_search.csv\",\n    \"americaneagle_search.csv\",\n    \"coach_search.csv\",\n    \"gap_search.csv\",\n    \"hm_search.csv\",\n    \"katespade_search.csv\",\n    \"michaelkors_search.csv\",\n    \"stuart_search.csv\"\n]\n\nfor file in files:\n    brand_name = file.replace(\"_search.csv\", \"\")\n    if brand_name == \"americaneagle\":\n        brand_name = \"American Eagle\"\n    elif brand_name == \"katespade\":\n        brand_name = \"Kate Spade\"\n    elif brand_name == \"michaelkors\":\n        brand_name = \"Michael Kors\"\n    elif brand_name == \"stuart\":\n        brand_name = \"Stuart Weitzman\"\n    elif brand_name == \"hm\":\n        brand_name = \"H&M\"\n    else:\n        brand_name = brand_name.capitalize()\n\n    search = pd.read_csv(path + file)\n    search[\"Date\"] = pd.to_datetime(search[\"Date\"])\n    search[\"Search Interest\"] = pd.to_numeric(search[\"Search Interest\"], errors=\"coerce\")\n    search[\"Brand\"] = brand_name\n\n    merged = pd.merge(search, monthly_sales, on=[\"Date\", \"Brand\"], how=\"inner\")\n\n    if len(merged) &gt;= 2:\n        corr, pval = pearsonr(merged[\"Search Interest\"], merged[\"Net Sales ($ Millions)\"])\n        print(f\"{brand_name}: Correlation = {round(corr, 3)} | P-Value = {round(pval, 4)}\")\n\n\nAbercrombie: Correlation = 0.476 | P-Value = 0.0006\nAmerican Eagle: Correlation = -0.619 | P-Value = 0.0\nCoach: Correlation = -0.162 | P-Value = 0.2658\nGap: Correlation = 0.311 | P-Value = 0.0299\nH&M: Correlation = 0.457 | P-Value = 0.001\nKate Spade: Correlation = -0.065 | P-Value = 0.6577\nMichael Kors: Correlation = -0.046 | P-Value = 0.7548\nStuart Weitzman: Correlation = -0.11 | P-Value = 0.5359\n\n\n\n\nCode\n!pip install seaborn\n\n\nRequirement already satisfied: seaborn in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (0.13.2)\nRequirement already satisfied: numpy!=1.24.0,&gt;=1.20 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from seaborn) (2.2.2)\nRequirement already satisfied: pandas&gt;=1.2 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from seaborn) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,&gt;=3.4 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from seaborn) (3.10.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (4.55.3)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.4.8)\nRequirement already satisfied: packaging&gt;=20.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (24.2)\nRequirement already satisfied: pillow&gt;=8 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (11.1.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (3.2.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from pandas&gt;=1.2-&gt;seaborn) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from pandas&gt;=1.2-&gt;seaborn) (2023.3)\nRequirement already satisfied: six&gt;=1.5 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.16.0)\n\n\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsearch_files = [\n    \"abercrombie_search.csv\",\n    \"americaneagle_search.csv\",\n    \"coach_search.csv\",\n    \"gap_search.csv\",\n    \"hm_search.csv\",\n    \"katespade_search.csv\",\n    \"michaelkors_search.csv\",\n    \"stuart_search.csv\"\n]\n\nsearch_data_cleaned = []\n\nfor file in search_files:\n    brand_name = file.replace(\"_search.csv\", \"\")\n    if brand_name == \"americaneagle\":\n        brand_name = \"American Eagle\"\n    elif brand_name == \"katespade\":\n        brand_name = \"Kate Spade\"\n    elif brand_name == \"michaelkors\":\n        brand_name = \"Michael Kors\"\n    elif brand_name == \"stuart\":\n        brand_name = \"Stuart Weitzman\"\n    elif brand_name == \"hm\":\n        brand_name = \"H&M\"\n    else:\n        brand_name = brand_name.capitalize()\n\n    df = pd.read_csv(path + file)\n    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n    df[\"Search Interest\"] = pd.to_numeric(df[\"Search Interest\"], errors=\"coerce\")\n    df[\"Brand\"] = brand_name\n    search_data_cleaned.append(df)\n\nall_search_data = pd.concat(search_data_cleaned, ignore_index=True)\n\nsearch_sales = pd.merge(all_search_data, monthly_sales, on=[\"Date\", \"Brand\"], how=\"inner\")\nsearch_sales = search_sales.dropna()\n\nplt.figure(figsize=(12, 8))\nsns.scatterplot(data=search_sales, x=\"Search Interest\", y=\"Net Sales ($ Millions)\", hue=\"Brand\")\nplt.title(\"Search Interest vs. Sales (All Brands)\")\nplt.xlabel(\"Google Search Interest\")\nplt.ylabel(\"Net Sales ($M)\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nluxury_brands = [\"Coach\", \"Kate Spade\", \"Stuart Weitzman\", \"Michael Kors\"]\nmass_market_brands = [\"Abercrombie\", \"American Eagle\", \"Gap\", \"H&M\"]\n\nsearch_sales = pd.merge(all_search_data, monthly_sales, on=[\"Date\", \"Brand\"], how=\"inner\")\nsearch_sales = search_sales.dropna()\nsearch_sales[\"Brand Type\"] = search_sales[\"Brand\"].apply(lambda x: \"Luxury\" if x in luxury_brands else \"Mass-Market\")\n\nluxury = search_sales[search_sales[\"Brand Type\"] == \"Luxury\"]\nmass = search_sales[search_sales[\"Brand Type\"] == \"Mass-Market\"]\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n\nsns.scatterplot(data=luxury, x=\"Search Interest\", y=\"Net Sales ($ Millions)\", hue=\"Brand\", ax=axes[0])\naxes[0].set_title(\"Luxury Brands\")\naxes[0].set_xlabel(\"Search Interest\")\naxes[0].set_ylabel(\"Net Sales ($M)\")\n\nsns.scatterplot(data=mass, x=\"Search Interest\", y=\"Net Sales ($ Millions)\", hue=\"Brand\", ax=axes[1])\naxes[1].set_title(\"Mass-Market Brands\")\naxes[1].set_xlabel(\"Search Interest\")\naxes[1].set_ylabel(\"\")\n\nplt.suptitle(\"Search Interest vs. Sales by Brand Category\", fontsize=16)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nwill just still to correlations bc this looks insane\n\n\nCode\npip install textblob\n\n\nCollecting textblob\n  Using cached textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting nltk&gt;=3.9 (from textblob)\n  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting click (from nltk&gt;=3.9-&gt;textblob)\n  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: joblib in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from nltk&gt;=3.9-&gt;textblob) (1.4.2)\nCollecting regex&gt;=2021.8.3 (from nltk&gt;=3.9-&gt;textblob)\n  Downloading regex-2024.11.6-cp312-cp312-macosx_10_13_x86_64.whl.metadata (40 kB)\nCollecting tqdm (from nltk&gt;=3.9-&gt;textblob)\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\nUsing cached textblob-0.19.0-py3-none-any.whl (624 kB)\nUsing cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\nDownloading regex-2024.11.6-cp312-cp312-macosx_10_13_x86_64.whl (288 kB)\nDownloading click-8.1.8-py3-none-any.whl (98 kB)\nDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nInstalling collected packages: tqdm, regex, click, nltk, textblob\nSuccessfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6 textblob-0.19.0 tqdm-4.67.1\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\npip install praw\n\n\nCollecting praw\n  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting prawcore&lt;3,&gt;=2.4 (from praw)\n  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\nCollecting update_checker&gt;=0.18 (from praw)\n  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: websocket-client&gt;=0.54.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from praw) (1.8.0)\nRequirement already satisfied: requests&lt;3.0,&gt;=2.6.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from prawcore&lt;3,&gt;=2.4-&gt;praw) (2.32.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0,&gt;=2.6.0-&gt;prawcore&lt;3,&gt;=2.4-&gt;praw) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0,&gt;=2.6.0-&gt;prawcore&lt;3,&gt;=2.4-&gt;praw) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0,&gt;=2.6.0-&gt;prawcore&lt;3,&gt;=2.4-&gt;praw) (2.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0,&gt;=2.6.0-&gt;prawcore&lt;3,&gt;=2.4-&gt;praw) (2024.12.14)\nDownloading praw-7.8.1-py3-none-any.whl (189 kB)\nDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\nDownloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\nInstalling collected packages: update_checker, prawcore, praw\nSuccessfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\nimport praw\n\nreddit = praw.Reddit(\n    client_id=\"8DsIW4DAuPnHNFSqaFj98A\",\n    client_secret=\"FkL4hqDJc81s5JSo02eoB65eqDCWsw\",\n    user_agent=\"CapstoneSentimentApp by janellemariie\"\n)\n\nfor post in reddit.subreddit(\"femalefashionadvice\").search(\"coach bag\", limit=5):\n    print(post.title)\n\n\nWhere do Coach sit in the tier of nice bags these days?\n“The Logic of Stupid Poor People”-how have you used fashion to navigate classism/racism?\nI spent a month planning a capsule wardobe for a 2 week trip in Asia that I gave up on after 4 days. Album included!\nYour guide to shopping The RealReal — a hot mess consignment website with some amazing gems.\nFound a (very worn) “Coach” bag at the thrift store. Assuming it’s fake, but curious how to tell?\n\n\n\n\nCode\nfrom datetime import datetime\n\ndef get_brand_sentiment(brand_keyword, subreddit=\"femalefashionadvice\", year=2021, quarters=[\"Q1\", \"Q2\"]):\n    result = []\n    quarter_dates = {\n        \"Q1\": (\"01-01\", \"03-31\"),\n        \"Q2\": (\"04-01\", \"06-30\"),\n        \"Q3\": (\"07-01\", \"09-30\"),\n        \"Q4\": (\"10-01\", \"12-31\"),\n    }\n\n    for q in quarters:\n        after = f\"{year}-{quarter_dates[q][0]}\"\n        before = f\"{year}-{quarter_dates[q][1]}\"\n        after_ts = int(datetime.strptime(after, \"%Y-%m-%d\").timestamp())\n        before_ts = int(datetime.strptime(before, \"%Y-%m-%d\").timestamp())\n\n        posts = reddit.subreddit(subreddit).search(brand_keyword, sort=\"new\", limit=100)\n        sentiments = []\n\n        for post in posts:\n            if after_ts &lt;= post.created_utc &lt;= before_ts:\n                text = post.title + \" \" + (post.selftext or \"\")\n                score = TextBlob(text).sentiment.polarity\n                sentiments.append(score)\n\n        avg_sentiment = sum(sentiments)/len(sentiments) if sentiments else 0\n        result.append({\n            \"Brand\": brand_keyword,\n            \"Quarter\": f\"{year} {q}\",\n            \"Num Posts\": len(sentiments),\n            \"Avg Sentiment\": round(avg_sentiment, 3)\n        })\n\n    return pd.DataFrame(result)\n\n\n\n\nCode\ncoach_df = get_brand_sentiment(\"coach bag\", year=2021, quarters=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\ncoach_df\n\n\n\n\n\n\n\n\n\nBrand\nQuarter\nNum Posts\nAvg Sentiment\n\n\n\n\n0\ncoach bag\n2021 Q1\n0\n0.000\n\n\n1\ncoach bag\n2021 Q2\n0\n0.000\n\n\n2\ncoach bag\n2021 Q3\n2\n0.134\n\n\n3\ncoach bag\n2021 Q4\n5\n0.223\n\n\n\n\n\n\n\n\n\nCode\ndef get_brand_sentiment_yearly(brand_keyword, subreddit=\"femalefashionadvice\", start_year=2012, end_year=2024):\n    results = []\n    for year in range(start_year, end_year + 1):\n        after = int(datetime(year, 1, 1).timestamp())\n        before = int(datetime(year, 12, 31).timestamp())\n\n        sentiments = []\n        post_count = 0\n\n        for post in reddit.subreddit(subreddit).search(brand_keyword, sort=\"new\", limit=1000):\n            if after &lt;= post.created_utc &lt;= before:\n                text = post.title + \" \" + (post.selftext or \"\")\n                score = TextBlob(text).sentiment.polarity\n                sentiments.append(score)\n                post_count += 1\n\n        avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0\n        results.append({\n            \"Brand\": brand_keyword,\n            \"Year\": year,\n            \"Num Posts\": post_count,\n            \"Avg Sentiment\": round(avg_sentiment, 3)\n        })\n\n    return pd.DataFrame(results)\n\n# Your 8 brand search terms\nbrand_keywords = {\n    \"Abercrombie\": \"abercrombie\",\n    \"American Eagle\": \"american eagle\",\n    \"Coach\": \"coach bag\",\n    \"Gap\": \"gap\",\n    \"H&M\": \"h&m\",\n    \"Kate Spade\": \"kate spade\",\n    \"Michael Kors\": \"michael kors\",\n    \"Stuart Weitzman\": \"stuart weitzman\"\n}\n\nall_brand_sentiment = pd.concat([\n    get_brand_sentiment_yearly(keyword).assign(Brand=brand)\n    for brand, keyword in brand_keywords.items()\n], ignore_index=True)\n\nall_brand_sentiment.to_csv(\"reddit_sentiment_by_year.csv\", index=False)\n\n\n\n\nCode\ndef get_reddit_sentiment_pushshift(keyword, subreddit, start_year=2012, end_year=2024):\n    results = []\n    for year in range(start_year, end_year + 1):\n        after = int(datetime(year, 1, 1).timestamp())\n        before = int(datetime(year + 1, 1, 1).timestamp())\n\n        url = f\"https://api.pushshift.io/reddit/search/submission/?q={keyword}&subreddit={subreddit}&after={after}&before={before}&size=500\"\n        response = requests.get(url)\n        data = response.json().get(\"data\", [])\n\n        sentiments = []\n        for post in data:\n            text = post.get(\"title\", \"\") + \" \" + post.get(\"selftext\", \"\")\n            score = TextBlob(text).sentiment.polarity\n            sentiments.append(score)\n\n        avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0\n        results.append({\n            \"Keyword\": keyword,\n            \"Subreddit\": subreddit,\n            \"Year\": year,\n            \"Num Posts\": len(sentiments),\n            \"Avg Sentiment\": round(avg_sentiment, 3)\n        })\n\n        time.sleep(1.5)\n    return pd.DataFrame(results)\n\nbrand_subreddits = {\n    \"Abercrombie\": (\"abercrombie\", \"malefashionadvice\"),\n    \"American Eagle\": (\"american eagle\", \"malefashionadvice\"),\n    \"Coach\": (\"coach\", \"Coach\"),\n    \"Gap\": (\"gap\", \"malefashionadvice\"),\n    \"H&M\": (\"h&m\", \"malefashionadvice\"),\n    \"Kate Spade\": (\"kate spade\", \"femalefashionadvice\"),\n    \"Michael Kors\": (\"michael kors\", \"michaelkors\"),\n    \"Stuart Weitzman\": (\"stuart weitzman\", \"femalefashionadvice\")\n}\n\nall_sentiments = pd.concat([\n    get_reddit_sentiment_pushshift(keyword=kw, subreddit=sub)\n    .assign(Brand=brand)\n    for brand, (kw, sub) in brand_subreddits.items()\n], ignore_index=True)\n\nall_sentiments.to_csv(\"reddit_sentiment_by_subreddit.csv\", index=False)\n\n\n\n\nCode\nyearly_sales = combined.groupby([\"Year\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().reset_index()\nyearly_sales[\"Sales Change (%)\"] = yearly_sales.groupby(\"Brand\")[\"Net Sales ($ Millions)\"].pct_change() * 100\n\nsentiment = pd.read_csv(path + \"femalefashionadvice.csv\")\n\nmerged = pd.merge(sentiment, yearly_sales, on=[\"Year\", \"Brand\"], how=\"inner\").dropna()\n\nbrands = merged[\"Brand\"].unique()\nfor brand in brands:\n    df = merged[merged[\"Brand\"] == brand]\n    if len(df) &gt;= 2:\n        corr, pval = pearsonr(df[\"Avg Sentiment\"], df[\"Sales Change (%)\"])\n        print(f\"{brand}: Correlation = {round(corr, 3)} | P-Value = {round(pval, 4)}\")\n\n\nAbercrombie: Correlation = 0.082 | P-Value = 0.8343\nAmerican Eagle: Correlation = -0.068 | P-Value = 0.8618\nCoach: Correlation = 0.223 | P-Value = 0.5639\nGap: Correlation = 0.102 | P-Value = 0.7944\nH&M: Correlation = -0.881 | P-Value = 0.0017\nKate Spade: Correlation = -0.261 | P-Value = 0.498\nMichael Kors: Correlation = 0.214 | P-Value = 0.5808\nStuart Weitzman: Correlation = 0.069 | P-Value = 0.861\n\n\n\n\nCode\ndef get_brand_sentiment_by_year(subreddit_name, brand, years=range(2016, 2024)):\n    results = []\n    for year in years:\n        start = int(datetime(year, 1, 1).timestamp())\n        end = int(datetime(year + 1, 1, 1).timestamp())\n        try:\n            posts = reddit.subreddit(subreddit_name).search(brand, sort=\"new\", limit=300, params={\"after\": start, \"before\": end})\n            texts = [post.title + \" \" + post.selftext for post in posts if hasattr(post, \"selftext\")]\n            sentiments = [TextBlob(text).sentiment.polarity for text in texts]\n            avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0\n            results.append({\n                \"Brand\": brand,\n                \"Year\": year,\n                \"Num Posts\": len(sentiments),\n                \"Avg Sentiment\": avg_sentiment\n            })\n        except Exception as e:\n            print(f\"Error pulling {brand} in r/{subreddit_name} for {year}: {e}\")\n            results.append({\n                \"Brand\": brand,\n                \"Year\": year,\n                \"Num Posts\": 0,\n                \"Avg Sentiment\": 0\n            })\n    return results\n\nall_sentiment_data = []\nfor brand, subreddit in brand_subreddits.items():\n    brand_data = get_brand_sentiment_by_year(subreddit, brand)\n    all_sentiment_data.extend(brand_data)\n\nsentiment_df = pd.DataFrame(all_sentiment_data)\n\nsentiment_df.to_csv(\"/Users/janellemarie/datasets/reddit_sentiment_by_year.csv\", index=False)\n\nprint(sentiment_df.head())\n\n\nError pulling Abercrombie in r/('abercrombie', 'malefashionadvice') for 2016: 'tuple' object has no attribute 'lower'\nError pulling Abercrombie in r/('abercrombie', 'malefashionadvice') for 2017: 'tuple' object has no attribute 'lower'\nError pulling Abercrombie in r/('abercrombie', 'malefashionadvice') for 2018: 'tuple' object has no attribute 'lower'\nError pulling Abercrombie in r/('abercrombie', 'malefashionadvice') for 2019: 'tuple' object has no attribute 'lower'\nError pulling Abercrombie in r/('abercrombie', 'malefashionadvice') for 2020: 'tuple' object has no attribute 'lower'\nError pulling Abercrombie in r/('abercrombie', 'malefashionadvice') for 2021: 'tuple' object has no attribute 'lower'\nError pulling Abercrombie in r/('abercrombie', 'malefashionadvice') for 2022: 'tuple' object has no attribute 'lower'\nError pulling Abercrombie in r/('abercrombie', 'malefashionadvice') for 2023: 'tuple' object has no attribute 'lower'\nError pulling American Eagle in r/('american eagle', 'malefashionadvice') for 2016: 'tuple' object has no attribute 'lower'\nError pulling American Eagle in r/('american eagle', 'malefashionadvice') for 2017: 'tuple' object has no attribute 'lower'\nError pulling American Eagle in r/('american eagle', 'malefashionadvice') for 2018: 'tuple' object has no attribute 'lower'\nError pulling American Eagle in r/('american eagle', 'malefashionadvice') for 2019: 'tuple' object has no attribute 'lower'\nError pulling American Eagle in r/('american eagle', 'malefashionadvice') for 2020: 'tuple' object has no attribute 'lower'\nError pulling American Eagle in r/('american eagle', 'malefashionadvice') for 2021: 'tuple' object has no attribute 'lower'\nError pulling American Eagle in r/('american eagle', 'malefashionadvice') for 2022: 'tuple' object has no attribute 'lower'\nError pulling American Eagle in r/('american eagle', 'malefashionadvice') for 2023: 'tuple' object has no attribute 'lower'\nError pulling Coach in r/('coach', 'Coach') for 2016: 'tuple' object has no attribute 'lower'\nError pulling Coach in r/('coach', 'Coach') for 2017: 'tuple' object has no attribute 'lower'\nError pulling Coach in r/('coach', 'Coach') for 2018: 'tuple' object has no attribute 'lower'\nError pulling Coach in r/('coach', 'Coach') for 2019: 'tuple' object has no attribute 'lower'\nError pulling Coach in r/('coach', 'Coach') for 2020: 'tuple' object has no attribute 'lower'\nError pulling Coach in r/('coach', 'Coach') for 2021: 'tuple' object has no attribute 'lower'\nError pulling Coach in r/('coach', 'Coach') for 2022: 'tuple' object has no attribute 'lower'\nError pulling Coach in r/('coach', 'Coach') for 2023: 'tuple' object has no attribute 'lower'\nError pulling Gap in r/('gap', 'malefashionadvice') for 2016: 'tuple' object has no attribute 'lower'\nError pulling Gap in r/('gap', 'malefashionadvice') for 2017: 'tuple' object has no attribute 'lower'\nError pulling Gap in r/('gap', 'malefashionadvice') for 2018: 'tuple' object has no attribute 'lower'\nError pulling Gap in r/('gap', 'malefashionadvice') for 2019: 'tuple' object has no attribute 'lower'\nError pulling Gap in r/('gap', 'malefashionadvice') for 2020: 'tuple' object has no attribute 'lower'\nError pulling Gap in r/('gap', 'malefashionadvice') for 2021: 'tuple' object has no attribute 'lower'\nError pulling Gap in r/('gap', 'malefashionadvice') for 2022: 'tuple' object has no attribute 'lower'\nError pulling Gap in r/('gap', 'malefashionadvice') for 2023: 'tuple' object has no attribute 'lower'\nError pulling H&M in r/('h&m', 'malefashionadvice') for 2016: 'tuple' object has no attribute 'lower'\nError pulling H&M in r/('h&m', 'malefashionadvice') for 2017: 'tuple' object has no attribute 'lower'\nError pulling H&M in r/('h&m', 'malefashionadvice') for 2018: 'tuple' object has no attribute 'lower'\nError pulling H&M in r/('h&m', 'malefashionadvice') for 2019: 'tuple' object has no attribute 'lower'\nError pulling H&M in r/('h&m', 'malefashionadvice') for 2020: 'tuple' object has no attribute 'lower'\nError pulling H&M in r/('h&m', 'malefashionadvice') for 2021: 'tuple' object has no attribute 'lower'\nError pulling H&M in r/('h&m', 'malefashionadvice') for 2022: 'tuple' object has no attribute 'lower'\nError pulling H&M in r/('h&m', 'malefashionadvice') for 2023: 'tuple' object has no attribute 'lower'\nError pulling Kate Spade in r/('kate spade', 'femalefashionadvice') for 2016: 'tuple' object has no attribute 'lower'\nError pulling Kate Spade in r/('kate spade', 'femalefashionadvice') for 2017: 'tuple' object has no attribute 'lower'\nError pulling Kate Spade in r/('kate spade', 'femalefashionadvice') for 2018: 'tuple' object has no attribute 'lower'\nError pulling Kate Spade in r/('kate spade', 'femalefashionadvice') for 2019: 'tuple' object has no attribute 'lower'\nError pulling Kate Spade in r/('kate spade', 'femalefashionadvice') for 2020: 'tuple' object has no attribute 'lower'\nError pulling Kate Spade in r/('kate spade', 'femalefashionadvice') for 2021: 'tuple' object has no attribute 'lower'\nError pulling Kate Spade in r/('kate spade', 'femalefashionadvice') for 2022: 'tuple' object has no attribute 'lower'\nError pulling Kate Spade in r/('kate spade', 'femalefashionadvice') for 2023: 'tuple' object has no attribute 'lower'\nError pulling Michael Kors in r/('michael kors', 'michaelkors') for 2016: 'tuple' object has no attribute 'lower'\nError pulling Michael Kors in r/('michael kors', 'michaelkors') for 2017: 'tuple' object has no attribute 'lower'\nError pulling Michael Kors in r/('michael kors', 'michaelkors') for 2018: 'tuple' object has no attribute 'lower'\nError pulling Michael Kors in r/('michael kors', 'michaelkors') for 2019: 'tuple' object has no attribute 'lower'\nError pulling Michael Kors in r/('michael kors', 'michaelkors') for 2020: 'tuple' object has no attribute 'lower'\nError pulling Michael Kors in r/('michael kors', 'michaelkors') for 2021: 'tuple' object has no attribute 'lower'\nError pulling Michael Kors in r/('michael kors', 'michaelkors') for 2022: 'tuple' object has no attribute 'lower'\nError pulling Michael Kors in r/('michael kors', 'michaelkors') for 2023: 'tuple' object has no attribute 'lower'\nError pulling Stuart Weitzman in r/('stuart weitzman', 'femalefashionadvice') for 2016: 'tuple' object has no attribute 'lower'\nError pulling Stuart Weitzman in r/('stuart weitzman', 'femalefashionadvice') for 2017: 'tuple' object has no attribute 'lower'\nError pulling Stuart Weitzman in r/('stuart weitzman', 'femalefashionadvice') for 2018: 'tuple' object has no attribute 'lower'\nError pulling Stuart Weitzman in r/('stuart weitzman', 'femalefashionadvice') for 2019: 'tuple' object has no attribute 'lower'\nError pulling Stuart Weitzman in r/('stuart weitzman', 'femalefashionadvice') for 2020: 'tuple' object has no attribute 'lower'\nError pulling Stuart Weitzman in r/('stuart weitzman', 'femalefashionadvice') for 2021: 'tuple' object has no attribute 'lower'\nError pulling Stuart Weitzman in r/('stuart weitzman', 'femalefashionadvice') for 2022: 'tuple' object has no attribute 'lower'\nError pulling Stuart Weitzman in r/('stuart weitzman', 'femalefashionadvice') for 2023: 'tuple' object has no attribute 'lower'\n         Brand  Year  Num Posts  Avg Sentiment\n0  Abercrombie  2016          0              0\n1  Abercrombie  2017          0              0\n2  Abercrombie  2018          0              0\n3  Abercrombie  2019          0              0\n4  Abercrombie  2020          0              0\n\n\n\n\nCode\nyearly_sales = combined.groupby([\"Year\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().reset_index()\nyearly_sales[\"Sales Change (%)\"] = yearly_sales.groupby(\"Brand\")[\"Net Sales ($ Millions)\"].pct_change() * 100\n\nsentiment = pd.read_csv(path + \"reddit_sentiment_by_year.csv\")\n\nmerged = pd.merge(sentiment, yearly_sales, on=[\"Year\", \"Brand\"], how=\"inner\").dropna()\n\nbrands = merged[\"Brand\"].unique()\nfor brand in brands:\n    df = merged[merged[\"Brand\"] == brand]\n    if len(df) &gt;= 2:\n        corr, pval = pearsonr(df[\"Avg Sentiment\"], df[\"Sales Change (%)\"])\n        print(f\"{brand}: Correlation = {round(corr, 3)} | P-Value = {round(pval, 4)}\")\n\n\nAbercrombie: Correlation = 0.183 | P-Value = 0.5695\nAmerican Eagle: Correlation = -0.031 | P-Value = 0.9249\nCoach: Correlation = 0.16 | P-Value = 0.6186\nGap: Correlation = 0.089 | P-Value = 0.7825\nH&M: Correlation = -0.696 | P-Value = 0.0119\nKate Spade: Correlation = -0.213 | P-Value = 0.5059\nMichael Kors: Correlation = 0.338 | P-Value = 0.2823\nStuart Weitzman: Correlation = 0.069 | P-Value = 0.861\n\n\n\n\nCode\nyearly_sales = combined.groupby([\"Year\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().reset_index()\nyearly_sales[\"Sales Change (%)\"] = yearly_sales.groupby(\"Brand\")[\"Net Sales ($ Millions)\"].pct_change() * 100\n\nsentiment = pd.read_csv(path + \"reddit_sentiment_by_year.csv\")\n\nmerged = pd.merge(sentiment, yearly_sales, on=[\"Year\", \"Brand\"], how=\"inner\").dropna()\n\nelection_years = [2016, 2020, 2024]\nfiltered = merged[merged[\"Year\"].isin(election_years)]\n\nresults = []\n\nfor brand in filtered[\"Brand\"].unique():\n    df = filtered[filtered[\"Brand\"] == brand]\n    if len(df) &gt;= 2:\n        corr, pval = pearsonr(df[\"Avg Sentiment\"], df[\"Sales Change (%)\"])\n        results.append({\n            \"Brand\": brand,\n            \"Correlation\": round(corr, 3),\n            \"P-Value\": round(pval, 4),\n            \"Years Analyzed\": len(df)\n        })\n\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(path + \"reddit_correlation_election_years.csv\", index=False)\nprint(results_df)\n\n\n             Brand  Correlation  P-Value  Years Analyzed\n0      Abercrombie        0.696   0.5099               3\n1   American Eagle       -0.079   0.9496               3\n2            Coach       -0.913   0.2673               3\n3              Gap        0.430   0.7172               3\n4              H&M       -0.942   0.2184               3\n5       Kate Spade        0.148   0.9052               3\n6     Michael Kors        0.791   0.4191               3\n7  Stuart Weitzman        0.794   0.4159               3\n\n\n\n\nCode\npath = \"/Users/janellemarie/datasets/\"\ncpi = pd.read_csv(path + \"MEDCPI.csv\")\n\ncpi[\"Date\"] = pd.to_datetime(cpi[\"observation_date\"])\ncpi = cpi.rename(columns={\"MEDCPIM158SFRBCLE\": \"Median CPI\"})\n\ncpi_yearly = cpi.set_index(\"Date\")[\"Median CPI\"].resample(\"Y\").mean().reset_index()\n\ncpi_yearly[\"Year\"] = cpi_yearly[\"Date\"].dt.year\ncpi_yearly = cpi_yearly[[\"Year\", \"Median CPI\"]]\n\nmerged = pd.merge(grouped_sales, cpi_yearly, on=\"Year\", how=\"inner\")\n\nplt.figure(figsize=(12, 6))\nplt.plot(merged[\"Year\"], merged[\"Luxury\"], label=\"Luxury Sales ($M)\", marker=\"o\")\nplt.plot(merged[\"Year\"], merged[\"Mass-Market\"], label=\"Mass-Market Sales ($M)\", linestyle=\"--\", marker=\"o\")\nplt.plot(merged[\"Year\"], merged[\"Median CPI\"] * 1000, label=\"Median CPI (scaled)\", linestyle=\"-.\", color=\"gray\")\n\n# Annotated Events\nevents = {\n    2012: \"2012 Election\",\n    2016: \"2016 Election\",\n    2020: \"COVID-19 & 2020 Election\",\n    2022: \"Inflation Surge\",\n    2024: \"2024 Election\"\n}\nfor year, label in events.items():\n    plt.axvline(x=year, color=\"gray\", linestyle=\":\", alpha=0.7)\n    plt.text(year, plt.ylim()[1]*0.75, label, rotation=45, ha=\"right\", fontsize=9)\n\nplt.title(\"Luxury vs. Mass-Market Sales & Inflation (Median CPI)\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Sales ($M) / CPI (scaled)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n/var/folders/fc/6pfhghc91czgj9kdp_1f19dc0000gn/T/ipykernel_19081/2397279174.py:7: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n  cpi_yearly = cpi.set_index(\"Date\")[\"Median CPI\"].resample(\"Y\").mean().reset_index()\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nsns.scatterplot(data=luxury, x=\"Median CPI\", y=\"Sales Change (%)\", hue=\"Brand\")\nsns.regplot(data=luxury, x=\"Median CPI\", y=\"Sales Change (%)\", scatter=False, color=\"black\", ci=None)\nplt.title(\"Luxury Brands: Sales % Change vs Median CPI\")\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nsns.scatterplot(data=mass, x=\"Median CPI\", y=\"Sales Change (%)\", hue=\"Brand\")\nsns.regplot(data=mass, x=\"Median CPI\", y=\"Sales Change (%)\", scatter=False, color=\"black\", ci=None)\nplt.title(\"Mass-Market Brands: Sales % Change vs Median CPI\")\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\n\npath = \"/Users/janellemarie/datasets/\"\ngdp = pd.read_csv(path + \"GDP_growth.csv\")\n\ngdp = gdp.rename(columns={\"observation_date\": \"Date\", \"A191RL1Q225SBEA\": \"GDP\"})\ngdp[\"Year\"] = pd.to_datetime(gdp[\"Date\"]).dt.year\ngdp = gdp.groupby(\"Year\")[\"GDP\"].mean().reset_index()\n\nmerged = pd.merge(sales, gdp, on=\"Year\", how=\"inner\")\n\nluxury = merged[merged[\"Luxury or Mass-Market\"] == \"Luxury\"]\nmass = merged[merged[\"Luxury or Mass-Market\"] == \"Mass-Market\"]\n\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nsns.scatterplot(data=luxury, x=\"GDP\", y=\"Sales Change (%)\", hue=\"Brand\")\nz_lux = np.polyfit(luxury[\"GDP\"], luxury[\"Sales Change (%)\"], 1)\nplt.plot(luxury[\"GDP\"], np.poly1d(z_lux)(luxury[\"GDP\"]), color=\"black\")\nplt.title(\"Luxury Brands: Sales % Change vs GDP Growth\")\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nsns.scatterplot(data=mass, x=\"GDP\", y=\"Sales Change (%)\", hue=\"Brand\")\nz_mass = np.polyfit(mass[\"GDP\"], mass[\"Sales Change (%)\"], 1)\nplt.plot(mass[\"GDP\"], np.poly1d(z_mass)(mass[\"GDP\"]), color=\"black\")\nplt.title(\"Mass-Market Brands: Sales % Change vs GDP Growth\")\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmerged = pd.merge(sales, cpi_yearly, on=\"Year\", how=\"inner\")\n\nplt.figure(figsize=(12, 8))\nsns.scatterplot(\n    data=merged,\n    x=\"Median CPI\",\n    y=\"Sales Change (%)\",\n    size=\"Net Sales ($ Millions)\",\n    hue=\"Luxury or Mass-Market\",\n    alpha=0.6,\n    sizes=(50, 1000)\n)\n\nplt.title(\"Bubble Plot: Sales Change vs Median CPI\\n(Bubble Size = Net Sales Volume)\")\nplt.xlabel(\"Median CPI\")\nplt.ylabel(\"Sales Change (%)\")\nplt.grid(True)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nsales_summary = sales.groupby([\"Year\", \"Luxury or Mass-Market\"])[\"Net Sales ($ Millions)\"].sum().unstack().reset_index()\n\nmerged = pd.merge(sales_summary, cpi, on=\"Year\", how=\"inner\")\n\nfig, ax1 = plt.subplots(figsize=(12, 6))\n\nax1.plot(merged[\"Year\"], merged[\"Luxury\"], color='orange', marker='o', label='Luxury Sales ($M)')\nax1.plot(merged[\"Year\"], merged[\"Mass-Market\"], color='orangered', marker='o', linestyle='--', label='Mass-Market Sales ($M)')\nax1.set_ylabel(\"Sales ($M)\", color='darkred')\nax1.tick_params(axis='y', labelcolor='darkred')\nax1.set_xlabel(\"Year\")\nax1.set_title(\"Luxury vs. Mass-Market Sales & Inflation\")\n\nax2 = ax1.twinx()\nax2.plot(merged[\"Year\"], merged[\"CPI\"], color='gray', linestyle='-.', marker='x', label='Median CPI')\nax2.set_ylabel(\"Median CPI\", color='gray')\nax2.tick_params(axis='y', labelcolor='gray')\n\nevents = {\n    2012: \"2012 Election\",\n    2016: \"2016 Election\",\n    2020: \"2020 Election\\n& COVID-19\",\n    2022: \"Inflation Surge\",\n    2024: \"2024 Election\"\n}\nfor year, label in events.items():\n    ax1.axvline(x=year, color='gray', linestyle='--', linewidth=1)\n    ax1.annotate(label,\n                 xy=(year, ax1.get_ylim()[1] * 0.85),\n                 rotation=45,\n                 ha='right',\n                 va='center',\n                 fontsize=8,\n                 color='black')\n\nlines1, labels1 = ax1.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax1.legend(lines1 + lines2, labels1 + labels2, loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\n\nquarterly_sales = pd.read_csv(\"/Users/janellemarie/datasets/quarterly_sales.csv\")\nhm_sales = pd.read_csv(\"/Users/janellemarie/datasets/hm_quarterly_sales_converted.csv\")\ngdp = pd.read_csv(\"/Users/janellemarie/datasets/GDP_growth.csv\")\ncpi = pd.read_csv(\"/Users/janellemarie/datasets/MEDCPI.csv\")\n\ngdp = gdp.rename(columns={\"observation_date\": \"Date\", \"A191RL1Q225SBEA\": \"GDP\"})\ngdp[\"Quarter\"] = pd.to_datetime(gdp[\"Date\"]).dt.to_period(\"Q\")\n\ncpi = cpi.rename(columns={\"observation_date\": \"Date\", \"MEDCPIM158SFRBCLE\": \"CPI\"})\ncpi[\"Quarter\"] = pd.to_datetime(cpi[\"Date\"]).dt.to_period(\"Q\")\ncpi = cpi.groupby(\"Quarter\")[\"CPI\"].mean().reset_index()\n\nmerged = quarterly_sales.copy()\nmerged.rename(columns={\"Fiscal Quarter\": \"Quarter\"}, inplace=True)\nmerged[\"Quarter\"] = merged[\"Year\"].astype(str) + merged[\"Quarter\"]\nmerged[\"Quarter\"] = pd.PeriodIndex(merged[\"Quarter\"], freq=\"Q\")\n\nmerged = merged.merge(gdp[[\"Quarter\", \"GDP\"]], on=\"Quarter\", how=\"left\")\nmerged = merged.merge(cpi, on=\"Quarter\", how=\"left\")\n\nelection_quarters = ['2012Q4', '2016Q4', '2020Q4', '2024Q4']\nmerged['Election_Quarter'] = merged['Quarter'].astype(str).isin(election_quarters)\n\nmerged['Net Sales ($ Millions)'] = pd.to_numeric(merged['Net Sales ($ Millions)'], errors='coerce')\n\n\nsns.set(style=\"whitegrid\")\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 6), sharex=True)\n\nsns.boxplot(x='Election_Quarter', y='GDP', data=merged, ax=axes[0])\naxes[0].set_title(\"GDP by Election vs. Non-Election Quarters\")\naxes[0].set_xlabel(\"\")\naxes[0].set_ylabel(\"GDP (Billions)\")\n\nsns.boxplot(x='Election_Quarter', y='CPI', data=merged, ax=axes[1])\naxes[1].set_title(\"CPI by Election vs. Non-Election Quarters\")\naxes[1].set_xlabel(\"\")\naxes[1].set_ylabel(\"Median CPI\")\n\nsns.boxplot(x='Election_Quarter', y='Net Sales ($ Millions)', data=merged, ax=axes[2])\naxes[2].set_title(\"Sales by Election vs. Non-Election Quarters\")\naxes[2].set_xlabel(\"\")\naxes[2].set_ylabel(\"Net Sales ($M)\")\n\nfor ax in axes:\n    ax.set_xticks([0, 1])\n    ax.set_xticklabels(['Non-Election', 'Election'])\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\npip install praw wordcloud matplotlib\n\n\nRequirement already satisfied: praw in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (7.8.1)\nCollecting wordcloud\n  Downloading wordcloud-1.9.4-cp312-cp312-macosx_10_13_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: matplotlib in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (3.10.0)\nRequirement already satisfied: prawcore&lt;3,&gt;=2.4 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from praw) (2.4.0)\nRequirement already satisfied: update_checker&gt;=0.18 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from praw) (0.18.0)\nRequirement already satisfied: websocket-client&gt;=0.54.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from praw) (1.8.0)\nRequirement already satisfied: numpy&gt;=1.6.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from wordcloud) (2.2.2)\nRequirement already satisfied: pillow in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from wordcloud) (11.1.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging&gt;=20.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib) (24.2)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: requests&lt;3.0,&gt;=2.6.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from prawcore&lt;3,&gt;=2.4-&gt;praw) (2.32.3)\nRequirement already satisfied: six&gt;=1.5 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0,&gt;=2.6.0-&gt;prawcore&lt;3,&gt;=2.4-&gt;praw) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0,&gt;=2.6.0-&gt;prawcore&lt;3,&gt;=2.4-&gt;praw) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0,&gt;=2.6.0-&gt;prawcore&lt;3,&gt;=2.4-&gt;praw) (2.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0,&gt;=2.6.0-&gt;prawcore&lt;3,&gt;=2.4-&gt;praw) (2024.12.14)\nDownloading wordcloud-1.9.4-cp312-cp312-macosx_10_13_x86_64.whl (173 kB)\nInstalling collected packages: wordcloud\nSuccessfully installed wordcloud-1.9.4\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\n# tutorial source: https://medium.com/mcd-unison/create-word-cloud-scraping-data-from-reddit-api-using-praw-and-spacy-b5c9c61c2d10\n\nimport praw\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n\nreddit = praw.Reddit(\n    client_id=\"8DsIW4DAuPnHNFSqaFj98A\",\n    client_secret=\"FkL4hqDJc81s5JSo02eoB65eqDCWsw\",\n    user_agent=\"CapstoneSentimentApp by janellemariie\"\n)\n\nbrand_keywords = {\n    \"Abercrombie\": \"abercrombie fashion\",\n    \"American Eagle\": \"american eagle outfit\",\n    \"Coach\": \"coach bag\",\n    \"Gap\": \"gap clothing\",\n    \"H&M\": \"hm haul\",\n    \"Kate Spade\": \"kate spade purse\",\n    \"Michael Kors\": \"michael kors bag\",\n    \"Stuart Weitzman\": \"stuart weitzman boots\"\n}\n\nsubreddits = [\"femalefashionadvice\", \"malefashionadvice\", \"frugalmalefashion\", \"trendygirl\", \"streetwear\"]\n\nextra_stopwords = {\n    \"https\", \"http\", \"www\", \"imgur\", \"com\", \"said\", \"one\", \"get\", \"know\", \"look\", \"thing\", \"think\", \"even\", \"go\", \"going\", \"also\"\n}\n\nstopwords = STOPWORDS.union(extra_stopwords)\nstopwords = stopwords.union({kw.lower() for kw in brand_keywords.values()})\n\nfor brand, query in brand_keywords.items():\n    combined_text = \"\"\n    for sub in subreddits:\n        try:\n            for post in reddit.subreddit(sub).search(query, sort=\"relevance\", limit=75):\n                if post.selftext and len(post.selftext.split()) &gt; 20:\n                    combined_text += post.title + \" \" + post.selftext + \" \"\n                elif len(post.title.split()) &gt; 5:\n                    combined_text += post.title + \" \"\n        except:\n            continue\n\n    if combined_text.strip():\n        wc = WordCloud(width=800, height=400, background_color=\"white\", stopwords=stopwords).generate(combined_text)\n        plt.figure(figsize=(10, 5))\n        plt.imshow(wc, interpolation='bilinear')\n        plt.axis('off')\n        plt.title(f\"{brand} Reddit Word Cloud\")\n        plt.show()\n    else:\n        print(f\"No results for {brand}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo results for H&M\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# tutorial source: https://medium.com/mcd-unison/create-word-cloud-scraping-data-from-reddit-api-using-praw-and-spacy-b5c9c61c2d10\n# tutorial source: https://medium.com/mcd-unison/create-word-cloud-scraping-data-from-reddit-api-using-praw-and-spacy-b5c9c61c2d10\nimport praw\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n\nreddit = praw.Reddit(\n    client_id=\"8DsIW4DAuPnHNFSqaFj98A\",\n    client_secret=\"FkL4hqDJc81s5JSo02eoB65eqDCWsw\",\n    user_agent=\"CapstoneSentimentApp by janellemariie\"\n)\n\nmass_market_brands = {\n    \"Abercrombie\": \"abercrombie fashion\",\n    \"American Eagle\": \"american eagle outfit\",\n    \"Gap\": \"gap clothing\",\n    \"H&M\": \"hm haul\"\n}\n\nluxury_brands = {\n    \"Coach\": \"coach bag\",\n    \"Kate Spade\": \"kate spade purse\",\n    \"Michael Kors\": \"michael kors bag\",\n    \"Stuart Weitzman\": \"stuart weitzman boots\"\n}\n\nsubreddits = [\"femalefashionadvice\", \"malefashionadvice\", \"frugalmalefashion\", \"trendygirl\", \"streetwear\"]\n\ndef fetch_text(keywords_dict):\n    combined = \"\"\n    for brand, query in keywords_dict.items():\n        for sub in subreddits:\n            try:\n                for post in reddit.subreddit(sub).search(query, sort=\"relevance\", limit=75):\n                    if post.selftext and len(post.selftext.split()) &gt; 20:\n                        combined += post.title + \" \" + post.selftext + \" \"\n                    elif len(post.title.split()) &gt; 5:\n                        combined += post.title + \" \"\n            except:\n                continue\n    return combined\n\nmass_text = fetch_text(mass_market_brands)\nluxury_text = fetch_text(luxury_brands)\n\ndescriptive_keywords = {\n    \"cute\", \"great\", \"nice\", \"soft\", \"quality\", \"durable\", \"affordable\", \"expensive\", \"trendy\",\n    \"versatile\", \"timeless\", \"cozy\", \"stylish\", \"classic\", \"reliable\", \"comfy\", \"flattering\",\n    \"minimal\", \"bold\", \"structured\", \"cheap\", \"worth\", \"iconic\", \"modern\", \"vintage\", \"beautiful\",\n    \"elegant\", \"perfect\", \"simple\", \"neutral\", \"amazing\", \"chic\", \"feminine\", \"masculine\", \"luxurious\"\n}\n\ndef keep_only_keywords(text, keyword_set):\n    words = text.lower().split()\n    return \" \".join([word.strip(\".,!?()[]\\\"'\") for word in words if word.strip(\".,!?()[]\\\"'\") in keyword_set])\n\nmass_filtered = keep_only_keywords(mass_text, descriptive_keywords)\nluxury_filtered = keep_only_keywords(luxury_text, descriptive_keywords)\n\nmass_wc = WordCloud(width=1000, height=500, background_color=\"white\").generate(mass_filtered)\nluxury_wc = WordCloud(width=1000, height=500, background_color=\"white\").generate(luxury_filtered)\n\nplt.figure(figsize=(18, 8))\n\nplt.subplot(1, 2, 1)\nplt.imshow(mass_wc, interpolation='bilinear')\nplt.axis('off')\nplt.title(\"Mass-Market Descriptive Discourse\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(luxury_wc, interpolation='bilinear')\nplt.axis('off')\nplt.title(\"Luxury Brand Descriptive Discourse\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\npip install spacy\n\n\nCollecting spacy\n  Downloading spacy-3.8.5-cp312-cp312-macosx_10_13_x86_64.whl.metadata (27 kB)\nCollecting spacy-legacy&lt;3.1.0,&gt;=3.0.11 (from spacy)\n  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\nCollecting spacy-loggers&lt;2.0.0,&gt;=1.0.0 (from spacy)\n  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\nCollecting murmurhash&lt;1.1.0,&gt;=0.28.0 (from spacy)\n  Downloading murmurhash-1.0.12-cp312-cp312-macosx_10_13_x86_64.whl.metadata (2.1 kB)\nCollecting cymem&lt;2.1.0,&gt;=2.0.2 (from spacy)\n  Downloading cymem-2.0.11-cp312-cp312-macosx_10_13_x86_64.whl.metadata (8.5 kB)\nCollecting preshed&lt;3.1.0,&gt;=3.0.2 (from spacy)\n  Downloading preshed-3.0.9-cp312-cp312-macosx_10_9_x86_64.whl.metadata (2.2 kB)\nCollecting thinc&lt;8.4.0,&gt;=8.3.4 (from spacy)\n  Downloading thinc-8.3.6-cp312-cp312-macosx_10_13_x86_64.whl.metadata (15 kB)\nCollecting wasabi&lt;1.2.0,&gt;=0.9.1 (from spacy)\n  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\nCollecting srsly&lt;3.0.0,&gt;=2.4.3 (from spacy)\n  Downloading srsly-2.5.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (19 kB)\nCollecting catalogue&lt;2.1.0,&gt;=2.0.6 (from spacy)\n  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\nCollecting weasel&lt;0.5.0,&gt;=0.1.0 (from spacy)\n  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\nCollecting typer&lt;1.0.0,&gt;=0.3.0 (from spacy)\n  Downloading typer-0.15.3-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from spacy) (4.67.1)\nRequirement already satisfied: numpy&gt;=1.19.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from spacy) (2.2.2)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from spacy) (2.32.3)\nCollecting pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4 (from spacy)\n  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\nRequirement already satisfied: jinja2 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from spacy) (3.1.5)\nRequirement already satisfied: setuptools in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from spacy) (72.1.0)\nRequirement already satisfied: packaging&gt;=20.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from spacy) (24.2)\nCollecting langcodes&lt;4.0.0,&gt;=3.2.0 (from spacy)\n  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\nCollecting language-data&gt;=1.2 (from langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy)\n  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\nCollecting annotated-types&gt;=0.6.0 (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy)\n  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy)\n  Downloading pydantic_core-2.33.2-cp312-cp312-macosx_10_12_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: typing-extensions&gt;=4.12.2 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy) (4.12.2)\nCollecting typing-inspection&gt;=0.4.0 (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy)\n  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy) (2.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy) (2024.12.14)\nCollecting blis&lt;1.4.0,&gt;=1.3.0 (from thinc&lt;8.4.0,&gt;=8.3.4-&gt;spacy)\n  Downloading blis-1.3.0-cp312-cp312-macosx_10_13_x86_64.whl.metadata (7.4 kB)\nCollecting confection&lt;1.0.0,&gt;=0.0.1 (from thinc&lt;8.4.0,&gt;=8.3.4-&gt;spacy)\n  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: click&gt;=8.0.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy) (8.1.8)\nCollecting shellingham&gt;=1.3.0 (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy)\n  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting rich&gt;=10.11.0 (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy)\n  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\nCollecting cloudpathlib&lt;1.0.0,&gt;=0.7.0 (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy)\n  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\nCollecting smart-open&lt;8.0.0,&gt;=5.2.1 (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy)\n  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from jinja2-&gt;spacy) (2.1.3)\nCollecting marisa-trie&gt;=1.1.0 (from language-data&gt;=1.2-&gt;langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy)\n  Downloading marisa_trie-1.2.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (9.0 kB)\nCollecting markdown-it-py&gt;=2.2.0 (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy)\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /opt/anaconda3/envs/capstone/lib/python3.12/site-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy) (2.15.1)\nCollecting wrapt (from smart-open&lt;8.0.0,&gt;=5.2.1-&gt;weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy)\n  Downloading wrapt-1.17.2-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.4 kB)\nCollecting mdurl~=0.1 (from markdown-it-py&gt;=2.2.0-&gt;rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy)\n  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\nDownloading spacy-3.8.5-cp312-cp312-macosx_10_13_x86_64.whl (6.3 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 13.5 MB/s eta 0:00:00a 0:00:01\nDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\nDownloading cymem-2.0.11-cp312-cp312-macosx_10_13_x86_64.whl (42 kB)\nDownloading langcodes-3.5.0-py3-none-any.whl (182 kB)\nDownloading murmurhash-1.0.12-cp312-cp312-macosx_10_13_x86_64.whl (27 kB)\nDownloading preshed-3.0.9-cp312-cp312-macosx_10_9_x86_64.whl (133 kB)\nDownloading pydantic-2.11.4-py3-none-any.whl (443 kB)\nDownloading pydantic_core-2.33.2-cp312-cp312-macosx_10_12_x86_64.whl (2.0 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 10.0 MB/s eta 0:00:00\nDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\nDownloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\nDownloading srsly-2.5.1-cp312-cp312-macosx_10_13_x86_64.whl (636 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 636.7/636.7 kB 19.3 MB/s eta 0:00:00\nDownloading thinc-8.3.6-cp312-cp312-macosx_10_13_x86_64.whl (890 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 890.2/890.2 kB 39.0 MB/s eta 0:00:00\nDownloading typer-0.15.3-py3-none-any.whl (45 kB)\nDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\nDownloading weasel-0.4.1-py3-none-any.whl (50 kB)\nDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nDownloading blis-1.3.0-cp312-cp312-macosx_10_13_x86_64.whl (7.0 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 24.4 MB/s eta 0:00:00a 0:00:01\nDownloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\nDownloading confection-0.1.5-py3-none-any.whl (35 kB)\nDownloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 24.6 MB/s eta 0:00:00a 0:00:01\nDownloading rich-14.0.0-py3-none-any.whl (243 kB)\nDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\nDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\nDownloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\nDownloading marisa_trie-1.2.1-cp312-cp312-macosx_10_13_x86_64.whl (190 kB)\nDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\nDownloading wrapt-1.17.2-cp312-cp312-macosx_10_13_x86_64.whl (38 kB)\nDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nInstalling collected packages: cymem, wrapt, wasabi, typing-inspection, spacy-loggers, spacy-legacy, shellingham, pydantic-core, murmurhash, mdurl, marisa-trie, cloudpathlib, catalogue, blis, annotated-types, srsly, smart-open, pydantic, preshed, markdown-it-py, language-data, rich, langcodes, confection, typer, thinc, weasel, spacy\nSuccessfully installed annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.12 preshed-3.0.9 pydantic-2.11.4 pydantic-core-2.33.2 rich-14.0.0 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 typer-0.15.3 typing-inspection-0.4.0 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCode\n!python -m spacy download en_core_web_sm\n\n\nCollecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 41.1 MB/s eta 0:00:00 0:00:01\nInstalling collected packages: en-core-web-sm\nSuccessfully installed en-core-web-sm-3.8.0\n✔ Download and installation successful\nYou can now load the package via spacy.load('en_core_web_sm')"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "From Coach to Old Navy: a Study on the Effects of Economic Events on Luxury vs. Mass-Market Sales",
    "section": "",
    "text": "Source: Unsplash.com"
  },
  {
    "objectID": "index.html#fashion-by-the-figures",
    "href": "index.html#fashion-by-the-figures",
    "title": "From Coach to Old Navy: a Study on the Effects of Economic Events on Luxury vs. Mass-Market Sales",
    "section": "Fashion by the Figures",
    "text": "Fashion by the Figures\nTo understand how consumer behavior changed across economic and political cycles, I relied on several key visualizations:\n\nSales Trends by Brand (2012–2024): A line graph showing net sales across eight major fashion brands.\nSales + Goodwill & Intangibles Over Time: Layered line plots comparing brand equity and sales.\nCOVID-19 Sales Impact Bar Chart: Sales drops and rebounds during early pandemic quarters.\nGoogle Trends vs. Sales: Relationship between public interest and revenue.\nReddit Sentiment vs. Sales: Community discourse’s connection to consumer activity.\nElection Year Boxplots: Visuals comparing CPI, GDP, and sales during political cycles.\nInflation & Sales (Dual Axis): Tracks CPI against luxury and mass-market revenue.\nReddit Word Clouds: Snapshot of consumer language by brand category.\n\n\nThreading the Timeline: Sales by Brand (2012–2024)\nYearly sales trends paint a clear picture of consumer behavior over time. This line graph shows yearly sales data for each brand included in the study. Mass-market brands like H&M and Gap clearly lead in overall volume, but the lines also reveal volatility, especially around 2020. In contrast, luxury brands like Coach and Michael Kors remain more stable over time, suggesting a loyal customer base even during global events.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfile_paths = {\n    \"goodwill\": \"/Users/janellemarie/capstone/data/goodwill_value.csv\",\n    \"yearly_sales\": \"/Users/janellemarie/capstone/data/yearly_sales.csv\",\n    \"quarterly_sales\": \"/Users/janellemarie/capstone/data/quarterly_sales.csv\",\n    \"h&m_goodwill\": \"/Users/janellemarie/capstone/data/hm_goodwill_usd.csv\",\n    \"h&m_quarterly_sales\": \"/Users/janellemarie/capstone/data/hm_quarterly_sales_converted.csv\",\n    \"h&m_sales\": \"/Users/janellemarie/capstone/data/hm_sales_converted.csv\",\n}\n\ndataframes = {name: pd.read_csv(path) for name, path in file_paths.items()}\n\ndataframes[\"h&m_quarterly_sales\"].rename(columns={\"Net Sales (USD Millions)\": \"Net Sales ($ Millions)\"}, inplace=True)\ndataframes[\"h&m_goodwill\"].rename(columns={\"Goodwill Value (USD Millions)\": \"Goodwill Value ($ Millions)\"}, inplace=True)\n\nh_m_quarterly_sales = dataframes[\"h&m_quarterly_sales\"][[\"Year\", \"Brand\", \"Luxury or Mass-Market\", \"Net Sales ($ Millions)\", \"Fiscal Quarter\"]]\nquarterly_sales = dataframes[\"quarterly_sales\"][[\"Year\", \"Brand\", \"Luxury or Mass-Market\", \"Net Sales ($ Millions)\", \"Fiscal Quarter\"]]\ncombined_quarterly_sales = pd.concat([quarterly_sales, h_m_quarterly_sales], ignore_index=True)\n\ncombined_quarterly_sales[\"Net Sales ($ Millions)\"] = (\n    combined_quarterly_sales[\"Net Sales ($ Millions)\"]\n    .astype(str)\n    .str.replace(\",\", \"\")\n    .astype(float)\n)\n\nquarterly_sales_grouped = combined_quarterly_sales.groupby([\"Year\", \"Luxury or Mass-Market\"])[\"Net Sales ($ Millions)\"].sum().unstack()\n\nh_m_goodwill = dataframes[\"h&m_goodwill\"][[\"Year\", \"Brand\", \"Luxury or Mass-Market\", \"Goodwill Value ($ Millions)\"]]\ngoodwill = dataframes[\"goodwill\"][[\"Year\", \"Brand\", \"Luxury or Mass-Market\", \"Goodwill Value ($ Millions)\"]]\ncombined_goodwill = pd.concat([goodwill, h_m_goodwill], ignore_index=True)\n\nquarterly_sales = dataframes[\"quarterly_sales\"]\nh_m_quarterly_sales = dataframes[\"h&m_quarterly_sales\"]\n\nh_m_quarterly_sales = h_m_quarterly_sales.rename(columns={\"Net Sales (USD Millions)\": \"Net Sales ($ Millions)\"})\ncombined_sales = pd.concat([quarterly_sales, h_m_quarterly_sales], ignore_index=True)\n\ncombined_sales[\"Net Sales ($ Millions)\"] = (\n    combined_sales[\"Net Sales ($ Millions)\"]\n    .astype(str)\n    .str.replace(\",\", \"\")\n    .astype(float)\n)\n\nsales_trends = combined_sales.groupby(\"Year\")[\"Net Sales ($ Millions)\"].sum().reset_index()\n\ncombined_sales[\"Brand\"] = combined_sales[\"Brand\"].str.strip()\n\ncombined_sales[\"Brand\"] = combined_sales[\"Brand\"].replace(\"Gap Inc.\", \"Gap\")\n\nsales_trends_by_brand = combined_sales.groupby([\"Year\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().unstack()\n\ncombined_sales.groupby([\"Year\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().unstack()\n\nplt.figure(figsize=(12, 6))\n\nfor brand in sales_trends_by_brand.columns:\n    plt.plot(sales_trends_by_brand.index, sales_trends_by_brand[brand], marker=\"o\", linestyle=\"-\", label=brand)\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Net Sales ($M)\")\nplt.title(\"Sales Trends by Brand (2012-2024)\")\nplt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\nplt.grid(True)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nTracking goodwill over time showed that certain luxury brands maintain consistently high brand equity. This kind of brand resilience, which is rooted in emotional appeal and customer trust, was not as evident in mass-market brands, which reported lower or fluctuating goodwill values. Despite shifts in sales, brands like Coach and Michael Kors maintained consistently high goodwill. This suggests that even during moments of uncertainty, these brands retained intangible value. Mass-market brands, on the other hand, reported minimal goodwill.\n\n\nCode\ncombined_goodwill[\"Goodwill Value ($ Millions)\"] = (\n    combined_goodwill[\"Goodwill Value ($ Millions)\"]\n    .astype(str)\n    .str.replace(\",\", \"\")\n    .astype(float)\n)\n\ngoodwill_grouped = combined_goodwill.groupby([\"Year\", \"Luxury or Mass-Market\"])[\"Goodwill Value ($ Millions)\"].sum().unstack()\n\nplt.figure(figsize=(12, 6))\n\nplt.plot(quarterly_sales_grouped.index, quarterly_sales_grouped[\"Luxury\"], label=\"Luxury Sales ($M)\", linestyle=\"-\", marker=\"o\")\nplt.plot(quarterly_sales_grouped.index, quarterly_sales_grouped[\"Mass-Market\"], label=\"Mass-Market Sales ($M)\", linestyle=\"--\", marker=\"o\")\n\nplt.plot(goodwill_grouped.index, goodwill_grouped[\"Luxury\"], label=\"Luxury Goodwill ($M)\", linestyle=\"-\", marker=\"s\")\nplt.plot(goodwill_grouped.index, goodwill_grouped[\"Mass-Market\"], label=\"Mass-Market Goodwill ($M)\", linestyle=\"--\", marker=\"s\")\n\nevents = {\n    2012: \"2012 Election\",\n    2016: \"2016 Election\",\n    2020: \"COVID-19 & 2020 Election\",\n    2022: \"Inflation Surge\",\n    2024: \"2024 Election\"\n}\nfor year, label in events.items():\n    plt.axvline(x=year, color=\"gray\", linestyle=\":\", alpha=0.7)\n    plt.text(year, 54000, label, rotation=25, ha=\"center\", va=\"top\", fontsize=9)\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Sales & Goodwill ($M)\")\nplt.title(\"Sales Trends and Goodwill Valuations (2012–2024)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThis visualization focuses on intangible assets beyond goodwill, like brand identity, customer relationships, and intellectual property. Once again, luxury brands dominate. The numbers reinforce the idea that luxury is built on more than product. It’s about identity, story, and legacy.\n\n\nCode\ngoodwill = pd.read_csv(\"/Users/janellemarie/datasets/goodwill_value.csv\")\nhm_goodwill = pd.read_csv(\"/Users/janellemarie/datasets/hm_goodwill_usd.csv\")\n\ncombined_intangibles = pd.concat([goodwill, hm_goodwill], ignore_index=True)\n\ncombined_intangibles[\"Intangible Assets ($ Millions)\"] = (\n    combined_intangibles[\"Intangible Assets ($ Millions)\"]\n    .astype(str)\n    .str.replace(\",\", \"\")\n    .astype(float)\n)\n\nintangibles_grouped = combined_intangibles.groupby([\"Year\", \"Luxury or Mass-Market\"])[\"Intangible Assets ($ Millions)\"].sum().unstack()\nintangibles_grouped.head()\n\nplt.figure(figsize=(12, 6))\n\nplt.plot(quarterly_sales_grouped.index, quarterly_sales_grouped[\"Luxury\"], label=\"Luxury Sales ($M)\", linestyle=\"-\", marker=\"o\")\nplt.plot(quarterly_sales_grouped.index, quarterly_sales_grouped[\"Mass-Market\"], label=\"Mass-Market Sales ($M)\", linestyle=\"--\", marker=\"o\")\n\nplt.plot(intangibles_grouped.index, intangibles_grouped[\"Luxury\"], label=\"Luxury Intangibles ($M)\", linestyle=\"-\", marker=\"s\")\nplt.plot(intangibles_grouped.index, intangibles_grouped[\"Mass-Market\"], label=\"Mass-Market Intangibles ($M)\", linestyle=\"--\", marker=\"s\")\n\nevents = {\n    2012: \"2012 Election\",\n    2016: \"2016 Election\",\n    2020: \"COVID-19 & 2020 Election\",\n    2022: \"Inflation Surge\",\n    2024: \"2024 Election\"\n}\n\nfor year, label in events.items():\n    plt.axvline(x=year, color=\"gray\", linestyle=\":\", alpha=0.7)\n    plt.text(year, 54000, label, rotation=25, ha=\"center\", va=\"top\", fontsize=9)\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Sales & Intangible Assets ($M)\")\nplt.title(\"Sales Trends and Intangible Asset Valuations (2012–2024)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nWhen the Malls Closed: COVID-19 Sales Impact\n\n\n\nCOVID-era fashion consumer\n\n\nWhen the pandemic hit, it disrupted everything including consumer habits. In this bar chart, I isolated the difference in sales between Q4 2019 and Q2 2020 to capture the immediate impact of COVID-19. H&M saw the sharpest decline, while brands like Coach and Stuart Weitzman actually experienced growth. This highlights the resilience of certain luxury brands in contrast to the vulnerability of mass-market players during crisis moments.\n\n\nCode\nsales_2019_q4 = combined_sales[(combined_sales[\"Year\"] == 2019) & (combined_sales[\"Fiscal Quarter\"] == \"Q4\")].groupby(\"Brand\")[\"Net Sales ($ Millions)\"].sum()\nsales_2020_q2 = combined_sales[(combined_sales[\"Year\"] == 2020) & (combined_sales[\"Fiscal Quarter\"] == \"Q2\")].groupby(\"Brand\")[\"Net Sales ($ Millions)\"].sum()\n\nsales_change_2020 = pd.DataFrame({\"Q4 2019 Sales\": sales_2019_q4, \"Q2 2020 Sales\": sales_2020_q2})\nsales_change_2020.fillna(0, inplace=True)\nsales_change_2020[\"Percentage Change\"] = ((sales_change_2020[\"Q2 2020 Sales\"] - sales_change_2020[\"Q4 2019 Sales\"]) / \nsales_change_2020[\"Q4 2019 Sales\"].replace(0, 1)) * 100\nsales_change_2020_sorted = sales_change_2020.sort_values(by=\"Percentage Change\")\n\ncolors_by_change = sales_change_2020_sorted[\"Percentage Change\"].apply(lambda x: \"teal\" if x &lt; 0 else \"gold\")\n\nplt.figure(figsize=(12, 8))\nplt.barh(sales_change_2020_sorted.index, sales_change_2020_sorted[\"Percentage Change\"], color=colors_by_change)\nplt.xlabel(\"Percentage Change in Sales (%)\")\nplt.ylabel(\"Brand\")\nplt.title(\"Sales Change from Q4 2019 to Q2 2020 (COVID-19 Impact)\")\nplt.axvline(x=0, color=\"black\", linewidth=1)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nGoogle Search Interest Correlation Analysis\nConsumer sentiment often translates into higher sales, but does it always? Abercrombie and H&M show a strong positive correlation, suggesting that curiosity and conversion were linked. Interestingly, American Eagle breaks that trend—more search interest actually aligned with fewer sales, which may reflect negative buzz or unmet consumer expectations.\n\n\nCode\nimport pandas as pd\nfrom scipy.stats import pearsonr\n\npath = \"/Users/janellemarie/datasets/\"\n\nsales = pd.read_csv(path + \"quarterly_sales.csv\")\nhm_sales = pd.read_csv(path + \"hm_quarterly_sales_converted.csv\")\nhm_sales = hm_sales.rename(columns={\"Net Sales (USD Millions)\": \"Net Sales ($ Millions)\"})\n\ncombined = pd.concat([sales, hm_sales], ignore_index=True)\ncombined[\"Net Sales ($ Millions)\"] = combined[\"Net Sales ($ Millions)\"].astype(str).str.replace(\",\", \"\").astype(float)\ncombined[\"Brand\"] = combined[\"Brand\"].str.strip().replace(\"Gap Inc.\", \"Gap\")\n\nquarter_map = {\"Q1\": \"01\", \"Q2\": \"04\", \"Q3\": \"07\", \"Q4\": \"10\"}\ncombined[\"Month\"] = combined[\"Fiscal Quarter\"].map(quarter_map)\ncombined[\"Date\"] = pd.to_datetime(combined[\"Year\"].astype(str) + \"-\" + combined[\"Month\"] + \"-01\")\n\nmonthly_sales = combined.groupby([\"Date\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().reset_index()\n\nfiles = [\n    \"abercrombie_search.csv\",\n    \"americaneagle_search.csv\",\n    \"coach_search.csv\",\n    \"gap_search.csv\",\n    \"hm_search.csv\",\n    \"katespade_search.csv\",\n    \"michaelkors_search.csv\",\n    \"stuart_search.csv\"\n]\n\nfor file in files:\n    brand_name = file.replace(\"_search.csv\", \"\")\n    if brand_name == \"americaneagle\":\n        brand_name = \"American Eagle\"\n    elif brand_name == \"katespade\":\n        brand_name = \"Kate Spade\"\n    elif brand_name == \"michaelkors\":\n        brand_name = \"Michael Kors\"\n    elif brand_name == \"stuart\":\n        brand_name = \"Stuart Weitzman\"\n    elif brand_name == \"hm\":\n        brand_name = \"H&M\"\n    else:\n        brand_name = brand_name.capitalize()\n\n    search = pd.read_csv(path + file)\n    search[\"Date\"] = pd.to_datetime(search[\"Date\"])\n    search[\"Search Interest\"] = pd.to_numeric(search[\"Search Interest\"], errors=\"coerce\")\n    search[\"Brand\"] = brand_name\n\n    merged = pd.merge(search, monthly_sales, on=[\"Date\", \"Brand\"], how=\"inner\")\n\n    if len(merged) &gt;= 2:\n        corr, pval = pearsonr(merged[\"Search Interest\"], merged[\"Net Sales ($ Millions)\"])\n        print(f\"{brand_name}: Correlation = {round(corr, 3)} | P-Value = {round(pval, 4)}\")\n\n\nAbercrombie: Correlation = 0.476 | P-Value = 0.0006\nAmerican Eagle: Correlation = -0.619 | P-Value = 0.0\nCoach: Correlation = -0.162 | P-Value = 0.2658\nGap: Correlation = 0.311 | P-Value = 0.0299\nH&M: Correlation = 0.457 | P-Value = 0.001\nKate Spade: Correlation = -0.065 | P-Value = 0.6577\nMichael Kors: Correlation = -0.046 | P-Value = 0.7548\nStuart Weitzman: Correlation = -0.11 | P-Value = 0.5359\n\n\n\n\nReddit Consumer Sentiment Correlation Analysis\nReddit offers a rich landscape of unfiltered consumer dialogue. To capture sentiment about the brands in this study, I collected posts from five fashion-focused subreddits:\n\nr/femalefashionadvice\nr/malefashionadvice\nr/frugalmalefashion\nr/trendygirl\nr/streetwear\n\nFor each brand, I used curated search queries that reflect how users typically discuss fashion items. For instance, queries like “abercrombie fashion” or “coach bag” were designed to surface relevant posts. Posts were filtered for length and relevance, and then sentiment analysis was performed using a Natural Language Processing model. I computed yearly sentiment averages and correlated them with annual sales data.\nH&M and American Eagle showed positive relationships between sentiment and sales, while Gap trailed behind. This suggests that positive community perception, especially on platforms like Reddit, may have some correlation to support stronger performance.\n\n\nCode\nyearly_sales = combined.groupby([\"Year\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().reset_index()\nyearly_sales[\"Sales Change (%)\"] = yearly_sales.groupby(\"Brand\")[\"Net Sales ($ Millions)\"].pct_change() * 100\n\nsentiment = pd.read_csv(path + \"reddit_sentiment_by_year.csv\")\n\nmerged = pd.merge(sentiment, yearly_sales, on=[\"Year\", \"Brand\"], how=\"inner\").dropna()\n\nbrands = merged[\"Brand\"].unique()\nfor brand in brands:\n    df = merged[merged[\"Brand\"] == brand]\n    if len(df) &gt;= 2:\n        corr, pval = pearsonr(df[\"Avg Sentiment\"], df[\"Sales Change (%)\"])\n        print(f\"{brand}: Correlation = {round(corr, 3)} | P-Value = {round(pval, 4)}\")\n\n\nAbercrombie: Correlation = 0.183 | P-Value = 0.5695\nAmerican Eagle: Correlation = -0.031 | P-Value = 0.9249\nCoach: Correlation = 0.16 | P-Value = 0.6186\nGap: Correlation = 0.089 | P-Value = 0.7825\nH&M: Correlation = -0.696 | P-Value = 0.0119\nKate Spade: Correlation = -0.213 | P-Value = 0.5059\nMichael Kors: Correlation = 0.338 | P-Value = 0.2823\nStuart Weitzman: Correlation = 0.069 | P-Value = 0.861\n\n\n\n\nElection Years on the Runway\nHow do politics shape our closets? This triple boxplot compares GDP, CPI, and sales across pre-election, election, and post-election quarters. While GDP and sales don’t shift dramatically, CPI tends to dip slightly during election quarters, possibly reflecting political efforts to stabilize consumer prices. This graph displays fashion consumption in a broader macroeconomic context.\n\n\nCode\nimport seaborn as sns\ngdp = pd.read_csv(\"/Users/janellemarie/datasets/GDP_growth.csv\")\ncpi = pd.read_csv(\"/Users/janellemarie/datasets/MEDCPI.csv\")\n\ngdp = gdp.rename(columns={\"observation_date\": \"Date\", \"A191RL1Q225SBEA\": \"GDP\"})\ngdp[\"Quarter\"] = pd.to_datetime(gdp[\"Date\"]).dt.to_period(\"Q\")\n\ncpi = cpi.rename(columns={\"observation_date\": \"Date\", \"MEDCPIM158SFRBCLE\": \"CPI\"})\ncpi[\"Quarter\"] = pd.to_datetime(cpi[\"Date\"]).dt.to_period(\"Q\")\ncpi = cpi.groupby(\"Quarter\")[\"CPI\"].mean().reset_index()\n\nmerged = quarterly_sales.copy()\nmerged.rename(columns={\"Fiscal Quarter\": \"Quarter\"}, inplace=True)\nmerged[\"Quarter\"] = merged[\"Year\"].astype(str) + merged[\"Quarter\"]\nmerged[\"Quarter\"] = pd.PeriodIndex(merged[\"Quarter\"], freq=\"Q\")\n\nmerged = merged.merge(gdp[[\"Quarter\", \"GDP\"]], on=\"Quarter\", how=\"left\")\nmerged = merged.merge(cpi, on=\"Quarter\", how=\"left\")\n\nelection_quarters = ['2012Q4', '2016Q4', '2020Q4', '2024Q4']\nmerged['Election_Quarter'] = merged['Quarter'].astype(str).isin(election_quarters)\n\nmerged['Net Sales ($ Millions)'] = pd.to_numeric(merged['Net Sales ($ Millions)'], errors='coerce')\n\n\nsns.set(style=\"whitegrid\")\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 6), sharex=True)\n\nsns.boxplot(x='Election_Quarter', y='GDP', data=merged, ax=axes[0])\naxes[0].set_title(\"GDP by Election vs. Non-Election Quarters\")\naxes[0].set_xlabel(\"\")\naxes[0].set_ylabel(\"GDP (Billions)\")\n\nsns.boxplot(x='Election_Quarter', y='CPI', data=merged, ax=axes[1])\naxes[1].set_title(\"CPI by Election vs. Non-Election Quarters\")\naxes[1].set_xlabel(\"\")\naxes[1].set_ylabel(\"Median CPI\")\n\nsns.boxplot(x='Election_Quarter', y='Net Sales ($ Millions)', data=merged, ax=axes[2])\naxes[2].set_title(\"Sales by Election vs. Non-Election Quarters\")\naxes[2].set_xlabel(\"\")\naxes[2].set_ylabel(\"Net Sales ($M)\")\n\nfor ax in axes:\n    ax.set_xticks([0, 1])\n    ax.set_xticklabels(['Non-Election', 'Election'])\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nWhen visualizing luxury and mass-market sales against median CPI, I found that luxury brands were more sensitive to inflation spikes, especially post-2022. Mass-market brands remained relatively steady in sales, with a notable dip during the 2020 election and pandemic before bouncing back. Luxury sales, while more volatile, show steady growth until 2022, when rising inflation appears to coincide with a decline. The pattern suggests that inflation might affect luxury consumers differently. Still, both sectors held their ground surprisingly well. I guess price tags don’t sway easily under economic pressure.\n\n\nCode\ncpi = pd.read_csv(\"/Users/janellemarie/datasets/MEDCPI.csv\")\ncpi[\"Date\"] = pd.to_datetime(cpi[\"observation_date\"])\ncpi = cpi.rename(columns={\"MEDCPIM158SFRBCLE\": \"Median CPI\"})\ncpi_yearly = cpi.set_index(\"Date\")[\"Median CPI\"].resample(\"Y\").mean().reset_index()\ncpi_yearly[\"Year\"] = cpi_yearly[\"Date\"].dt.year\ncpi_yearly = cpi_yearly[[\"Year\", \"Median CPI\"]]\n\nsales = pd.read_csv(\"/Users/janellemarie/datasets/yearly_sales.csv\")\n\nif \"Year\" not in sales.columns:\n    sales[\"Year\"] = pd.to_datetime(sales[\"Date\"]).dt.year\nelse:\n    sales[\"Year\"] = sales[\"Year\"].astype(int)\n\nsales_summary = sales.groupby([\"Year\", \"Luxury or Mass-Market\"])[\"Net Sales ($ Millions)\"].sum().unstack().reset_index()\n\nmerged = pd.merge(sales_summary, cpi_yearly, on=\"Year\", how=\"inner\").rename(columns={\"Median CPI\": \"CPI\"})\nmerged = merged[merged[\"Year\"].between(2012, 2024)]\n\nfig, ax1 = plt.subplots(figsize=(12, 6))\nax1.plot(merged[\"Year\"], merged[\"Luxury\"], color='orange', marker='o', label='Luxury Sales ($M)')\nax1.plot(merged[\"Year\"], merged[\"Mass-Market\"], color='orangered', marker='o', linestyle='--', label='Mass-Market Sales ($M)')\nax1.set_ylabel(\"Sales ($M)\", color='darkred')\nax1.tick_params(axis='y', labelcolor='darkred')\nax1.set_xlabel(\"Year\")\nax1.set_title(\"Luxury vs. Mass-Market Sales & Inflation\")\n\nax2 = ax1.twinx()\nax2.plot(merged[\"Year\"], merged[\"CPI\"], color='gray', linestyle='-.', marker='x', label='Median CPI')\nax2.set_ylabel(\"Median CPI\", color='gray')\nax2.tick_params(axis='y', labelcolor='gray')\n\nevents = {2012: \"2012 Election\", 2016: \"2016 Election\", 2020: \"2020 Election\\n& COVID-19\", 2022: \"Inflation Surge\", 2024: \"2024 Election\"}\nfor year, label in events.items():\n    ax1.axvline(x=year, color='gray', linestyle='--', linewidth=1)\n    ax1.annotate(label, xy=(year, ax1.get_ylim()[1] * 0.85), rotation=45, ha='right', va='center', fontsize=8, color='black')\n\nlines1, labels1 = ax1.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax1.legend(lines1 + lines2, labels1 + labels2, loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nReddit, but Make It Fashion\nFinally, I explored the language of fashion. Using descriptive words from Reddit posts, I created word clouds that visualized how people talked about different brand categories. Together, these visuals show how people talk about fashion very differently depending on the brand category.\n\n\nCode\n## tutorial source: https://medium.com/mcd-unison/create-word-cloud-scraping-data-from-reddit-api-using-praw-and-spacy-b5c9c61c2d10\nimport praw\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n\nreddit = praw.Reddit(\n    client_id=\"8DsIW4DAuPnHNFSqaFj98A\",\n    client_secret=\"FkL4hqDJc81s5JSo02eoB65eqDCWsw\",\n    user_agent=\"CapstoneSentimentApp by janellemariie\"\n)\n\nmass_market_brands = {\n    \"Abercrombie\": \"abercrombie fashion\",\n    \"American Eagle\": \"american eagle outfit\",\n    \"Gap\": \"gap clothing\",\n    \"H&M\": \"hm haul\"\n}\n\nluxury_brands = {\n    \"Coach\": \"coach bag\",\n    \"Kate Spade\": \"kate spade purse\",\n    \"Michael Kors\": \"michael kors bag\",\n    \"Stuart Weitzman\": \"stuart weitzman boots\"\n}\n\nsubreddits = [\"femalefashionadvice\", \"malefashionadvice\", \"frugalmalefashion\", \"trendygirl\", \"streetwear\"]\n\ndef fetch_text(keywords_dict):\n    combined = \"\"\n    for brand, query in keywords_dict.items():\n        for sub in subreddits:\n            try:\n                for post in reddit.subreddit(sub).search(query, sort=\"relevance\", limit=75):\n                    if post.selftext and len(post.selftext.split()) &gt; 20:\n                        combined += post.title + \" \" + post.selftext + \" \"\n                    elif len(post.title.split()) &gt; 5:\n                        combined += post.title + \" \"\n            except:\n                continue\n    return combined\n\nmass_text = fetch_text(mass_market_brands)\nluxury_text = fetch_text(luxury_brands)\n\ndescriptive_keywords = {\n    \"cute\", \"great\", \"nice\", \"soft\", \"quality\", \"durable\", \"affordable\", \"expensive\", \"trendy\",\n    \"versatile\", \"timeless\", \"cozy\", \"stylish\", \"classic\", \"reliable\", \"comfy\", \"flattering\",\n    \"minimal\", \"bold\", \"structured\", \"cheap\", \"worth\", \"iconic\", \"modern\", \"vintage\", \"beautiful\",\n    \"elegant\", \"perfect\", \"simple\", \"neutral\", \"amazing\", \"chic\", \"feminine\", \"masculine\", \"luxurious\"\n}\n\ndef keep_only_keywords(text, keyword_set):\n    words = text.lower().split()\n    return \" \".join([word.strip(\".,!?()[]\\\"'\") for word in words if word.strip(\".,!?()[]\\\"'\") in keyword_set])\n\nmass_filtered = keep_only_keywords(mass_text, descriptive_keywords)\nluxury_filtered = keep_only_keywords(luxury_text, descriptive_keywords)\n\nmass_wc = WordCloud(width=1000, height=500, background_color=\"white\").generate(mass_filtered)\nluxury_wc = WordCloud(width=1000, height=500, background_color=\"white\").generate(luxury_filtered)\n\nplt.figure(figsize=(18, 8))\n\nplt.subplot(1, 2, 1)\nplt.imshow(mass_wc, interpolation='bilinear')\nplt.axis('off')\nplt.title(\"Mass-Market Descriptive Discourse\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(luxury_wc, interpolation='bilinear')\nplt.axis('off')\nplt.title(\"Luxury Brand Descriptive Discourse\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "index.html#final-thoughts",
    "href": "index.html#final-thoughts",
    "title": "From Coach to Old Navy: a Study on the Effects of Economic Events on Luxury vs. Mass-Market Sales",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nI went into this project with little confidence. I chose a topic I cared deeply about, knowing it would involve more manual work and messier data than most. The data cleaning process was frustrating at times and pushed me to the edge of burnout, but in the end, I’m glad I followed my instincts. This project reminded me that research feels more meaningful when it’s rooted in something personal to me.\nLooking ahead, I hope to expand this work by exploring the fast fashion boom in the years following COVID-19. I’m especially interested in how sustainability efforts have evolved during this time and what that means for consumers, brands, and the planet. There’s still so much to uncover in the space where economics and clothing intersect."
  },
  {
    "objectID": "results/RQ1RQ2.html",
    "href": "results/RQ1RQ2.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All Code\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfile_paths = {\n    \"goodwill\": \"/Users/janellemarie/datasets/goodwill_value.csv\",\n    \"yearly_sales\": \"/Users/janellemarie/datasets/yearly_sales.csv\",\n    \"quarterly_sales\": \"/Users/janellemarie/datasets/quarterly_sales.csv\",\n    \"h&m_goodwill\": \"/Users/janellemarie/datasets/hm_goodwill_usd.csv\",\n    \"h&m_quarterly_sales\": \"/Users/janellemarie/datasets/hm_quarterly_sales_converted.csv\",\n    \"h&m_sales\": \"/Users/janellemarie/datasets/hm_sales_converted.csv\",\n}\n\ndataframes = {name: pd.read_csv(path) for name, path in file_paths.items()}\n\ndataframes[\"h&m_quarterly_sales\"].rename(columns={\"Net Sales (USD Millions)\": \"Net Sales ($ Millions)\"}, inplace=True)\ndataframes[\"h&m_goodwill\"].rename(columns={\"Goodwill Value (USD Millions)\": \"Goodwill Value ($ Millions)\"}, inplace=True)\n\nh_m_quarterly_sales = dataframes[\"h&m_quarterly_sales\"][[\"Year\", \"Brand\", \"Luxury or Mass-Market\", \"Net Sales ($ Millions)\", \"Fiscal Quarter\"]]\nquarterly_sales = dataframes[\"quarterly_sales\"][[\"Year\", \"Brand\", \"Luxury or Mass-Market\", \"Net Sales ($ Millions)\", \"Fiscal Quarter\"]]\ncombined_quarterly_sales = pd.concat([quarterly_sales, h_m_quarterly_sales], ignore_index=True)\n\ncombined_quarterly_sales[\"Net Sales ($ Millions)\"] = (\n    combined_quarterly_sales[\"Net Sales ($ Millions)\"]\n    .astype(str)\n    .str.replace(\",\", \"\")\n    .astype(float)\n)\n\nquarterly_sales_grouped = combined_quarterly_sales.groupby([\"Year\", \"Luxury or Mass-Market\"])[\"Net Sales ($ Millions)\"].sum().unstack()\n\nh_m_goodwill = dataframes[\"h&m_goodwill\"][[\"Year\", \"Brand\", \"Luxury or Mass-Market\", \"Goodwill Value ($ Millions)\"]]\ngoodwill = dataframes[\"goodwill\"][[\"Year\", \"Brand\", \"Luxury or Mass-Market\", \"Goodwill Value ($ Millions)\"]]\ncombined_goodwill = pd.concat([goodwill, h_m_goodwill], ignore_index=True)\n\ncombined_goodwill[\"Goodwill Value ($ Millions)\"] = (\n    combined_goodwill[\"Goodwill Value ($ Millions)\"]\n    .astype(str)\n    .str.replace(\",\", \"\")\n    .astype(float)\n)\n\ngoodwill_grouped = combined_goodwill.groupby([\"Year\", \"Luxury or Mass-Market\"])[\"Goodwill Value ($ Millions)\"].sum().unstack()\n\nplt.figure(figsize=(12, 6))\n\nplt.plot(quarterly_sales_grouped.index, quarterly_sales_grouped[\"Luxury\"], label=\"Luxury Sales ($M)\", linestyle=\"-\", marker=\"o\")\nplt.plot(quarterly_sales_grouped.index, quarterly_sales_grouped[\"Mass-Market\"], label=\"Mass-Market Sales ($M)\", linestyle=\"--\", marker=\"o\")\n\nplt.plot(goodwill_grouped.index, goodwill_grouped[\"Luxury\"], label=\"Luxury Goodwill ($M)\", linestyle=\"-\", marker=\"s\")\nplt.plot(goodwill_grouped.index, goodwill_grouped[\"Mass-Market\"], label=\"Mass-Market Goodwill ($M)\", linestyle=\"--\", marker=\"s\")\n\nevents = {\n    2012: \"2012 Election\",\n    2016: \"2016 Election\",\n    2020: \"COVID-19 & 2020 Election\",\n    2022: \"Inflation Surge\",\n    2024: \"2024 Election\"\n}\nfor year, label in events.items():\n    plt.axvline(x=year, color=\"gray\", linestyle=\":\", alpha=0.7)\n    plt.text(year, 54000, label, rotation=25, ha=\"center\", va=\"top\", fontsize=9)\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Sales & Goodwill ($M)\")\nplt.title(\"Sales Trends and Goodwill Valuations (2012-2024)\")\nplt.legend()\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ngoodwill = pd.read_csv(\"/Users/janellemarie/datasets/goodwill_value.csv\")\nhm_goodwill = pd.read_csv(\"/Users/janellemarie/datasets/hm_goodwill_usd.csv\")\n\ncombined_intangibles = pd.concat([goodwill, hm_goodwill], ignore_index=True)\n\ncombined_intangibles[\"Intangible Assets ($ Millions)\"] = (\n    combined_intangibles[\"Intangible Assets ($ Millions)\"]\n    .astype(str)\n    .str.replace(\",\", \"\")\n    .astype(float)\n)\n\nintangibles_grouped = combined_intangibles.groupby([\"Year\", \"Luxury or Mass-Market\"])[\"Intangible Assets ($ Millions)\"].sum().unstack()\nintangibles_grouped.head()\n\nplt.figure(figsize=(12, 6))\n\nplt.plot(quarterly_sales_grouped.index, quarterly_sales_grouped[\"Luxury\"], label=\"Luxury Sales ($M)\", linestyle=\"-\", marker=\"o\")\nplt.plot(quarterly_sales_grouped.index, quarterly_sales_grouped[\"Mass-Market\"], label=\"Mass-Market Sales ($M)\", linestyle=\"--\", marker=\"o\")\n\nplt.plot(intangibles_grouped.index, intangibles_grouped[\"Luxury\"], label=\"Luxury Intangibles ($M)\", linestyle=\"-\", marker=\"s\")\nplt.plot(intangibles_grouped.index, intangibles_grouped[\"Mass-Market\"], label=\"Mass-Market Intangibles ($M)\", linestyle=\"--\", marker=\"s\")\n\nevents = {\n    2012: \"2012 Election\",\n    2016: \"2016 Election\",\n    2020: \"COVID-19 & 2020 Election\",\n    2022: \"Inflation Surge\",\n    2024: \"2024 Election\"\n}\n\nfor year, label in events.items():\n    plt.axvline(x=year, color=\"gray\", linestyle=\":\", alpha=0.7)\n    plt.text(year, 54000, label, rotation=25, ha=\"center\", va=\"top\", fontsize=9)\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Sales & Intangible Assets ($M)\")\nplt.title(\"Sales Trends and Intangible Asset Valuations (2012–2024)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nquarterly_sales = dataframes[\"quarterly_sales\"]\nh_m_quarterly_sales = dataframes[\"h&m_quarterly_sales\"]\n\nh_m_quarterly_sales = h_m_quarterly_sales.rename(columns={\"Net Sales (USD Millions)\": \"Net Sales ($ Millions)\"})\ncombined_sales = pd.concat([quarterly_sales, h_m_quarterly_sales], ignore_index=True)\n\ncombined_sales[\"Net Sales ($ Millions)\"] = (\n    combined_sales[\"Net Sales ($ Millions)\"]\n    .astype(str)\n    .str.replace(\",\", \"\")\n    .astype(float)\n)\n\nsales_trends = combined_sales.groupby(\"Year\")[\"Net Sales ($ Millions)\"].sum().reset_index()\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.plot(sales_trends[\"Year\"], sales_trends[\"Net Sales ($ Millions)\"], marker=\"o\", linestyle=\"-\", color=\"blue\")\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Total Net Sales ($M)\")\nplt.title(\"Overall Sales Trends (2012–2024)\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ncombined_sales[\"Brand\"] = combined_sales[\"Brand\"].str.strip()\n\ncombined_sales[\"Brand\"] = combined_sales[\"Brand\"].replace(\"Gap Inc.\", \"Gap\")\n\nsales_trends_by_brand = combined_sales.groupby([\"Year\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().unstack()\n\ncombined_sales.groupby([\"Year\", \"Brand\"])[\"Net Sales ($ Millions)\"].sum().unstack()\n\nplt.figure(figsize=(12, 6))\n\nfor brand in sales_trends_by_brand.columns:\n    plt.plot(sales_trends_by_brand.index, sales_trends_by_brand[brand], marker=\"o\", linestyle=\"-\", label=brand)\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Net Sales ($M)\")\nplt.title(\"Sales Trends by Brand (2012-2024)\")\nplt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\nplt.grid(True)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nsales_2019_q4 = combined_sales[(combined_sales[\"Year\"] == 2019) & (combined_sales[\"Fiscal Quarter\"] == \"Q4\")].groupby(\"Brand\")[\"Net Sales ($ Millions)\"].sum()\nsales_2020_q2 = combined_sales[(combined_sales[\"Year\"] == 2020) & (combined_sales[\"Fiscal Quarter\"] == \"Q2\")].groupby(\"Brand\")[\"Net Sales ($ Millions)\"].sum()\n\nsales_change_2020 = pd.DataFrame({\"Q4 2019 Sales\": sales_2019_q4, \"Q2 2020 Sales\": sales_2020_q2})\nsales_change_2020.fillna(0, inplace=True)\nsales_change_2020[\"Percentage Change\"] = ((sales_change_2020[\"Q2 2020 Sales\"] - sales_change_2020[\"Q4 2019 Sales\"]) / \n                                          sales_change_2020[\"Q4 2019 Sales\"].replace(0, 1)) * 100\nsales_change_2020_sorted = sales_change_2020.sort_values(by=\"Percentage Change\")\n\ncolors_by_change = sales_change_2020_sorted[\"Percentage Change\"].apply(lambda x: \"teal\" if x &lt; 0 else \"gold\")\n\nplt.figure(figsize=(12, 8))\nplt.barh(sales_change_2020_sorted.index, sales_change_2020_sorted[\"Percentage Change\"], color=colors_by_change)\nplt.xlabel(\"Percentage Change in Sales (%)\")\nplt.ylabel(\"Brand\")\nplt.title(\"Sales Change from Q4 2019 to Q2 2020 (COVID-19 Impact)\")\nplt.axvline(x=0, color=\"black\", linewidth=1)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nsales_2021_q1 = combined_sales[(combined_sales[\"Year\"] == 2021) & (combined_sales[\"Fiscal Quarter\"] == \"Q1\")].groupby(\"Brand\")[\"Net Sales ($ Millions)\"].sum()\nsales_2021_q2 = combined_sales[(combined_sales[\"Year\"] == 2021) & (combined_sales[\"Fiscal Quarter\"] == \"Q2\")].groupby(\"Brand\")[\"Net Sales ($ Millions)\"].sum()\n\nsales_change_2021 = pd.DataFrame({\"Q1 2021 Sales\": sales_2021_q1, \"Q2 2021 Sales\": sales_2021_q2})\nsales_change_2021.fillna(0, inplace=True)\nsales_change_2021[\"Percentage Change\"] = ((sales_change_2021[\"Q2 2021 Sales\"] - sales_change_2021[\"Q1 2021 Sales\"]) /\n                                          sales_change_2021[\"Q1 2021 Sales\"].replace(0, 1)) * 100\nsales_change_2021_sorted = sales_change_2021.sort_values(by=\"Percentage Change\")\n\ncolors_2021 = sales_change_2021_sorted[\"Percentage Change\"].apply(lambda x: \"blue\" if x &lt; 0 else \"gold\")\n\nplt.figure(figsize=(12, 8))\nplt.barh(sales_change_2021_sorted.index, sales_change_2021_sorted[\"Percentage Change\"], color=colors_2021)\nplt.xlabel(\"Percentage Change in Sales (%)\")\nplt.ylabel(\"Brand\")\nplt.title(\"Sales Change from Q1 to Q2 2021 (Post-Lockdown Boom)\")\nplt.axvline(x=0, color=\"black\", linewidth=1)\nplt.show()"
  },
  {
    "objectID": "results/readme.html",
    "href": "results/readme.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\nThis is a placeholder file. Results should go in the results directory."
  }
]